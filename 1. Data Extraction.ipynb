{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "#FIrst step is to download nltk and all the available packages and corpora.\n",
    "\n",
    "import nltk\n",
    "nltk.download()\n",
    "%config IPCompleter.greedy=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For extracting data from websites or some html pages Import beautifulsoup\n",
    "\n",
    "import urllib.request as r\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def scraptext_from_url(url):\n",
    "    page = requests.get(url).text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    text = [p.text for p in soup.find(class_=\"mw-parser-output\").find_all('p')]\n",
    "    return text\n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/Adam%27s_Bridge\"\n",
    "text = scraptext_from_url(url)\n",
    "finaltext = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.txt\n",
      "all-exchanges-strings.lc.txt\n",
      "all-orgs-strings.lc.txt\n",
      "all-people-strings.lc.txt\n",
      "all-places-strings.lc.txt\n",
      "all-topics-strings.lc.txt\n",
      "cat-descriptions_120396.txt\n",
      "feldman-cia-worldfactbook-data.txt\n",
      "lewis.dtd\n",
      "reut2-000.sgm\n",
      "reut2-001.sgm\n",
      "reut2-002.sgm\n",
      "reut2-003.sgm\n",
      "reut2-004.sgm\n",
      "reut2-005.sgm\n",
      "reut2-006.sgm\n",
      "reut2-007.sgm\n",
      "reut2-008.sgm\n",
      "reut2-009.sgm\n",
      "reut2-010.sgm\n",
      "reut2-011.sgm\n",
      "reut2-012.sgm\n",
      "reut2-013.sgm\n",
      "reut2-014.sgm\n",
      "reut2-015.sgm\n",
      "reut2-016.sgm\n",
      "reut2-017.sgm\n",
      "reut2-018.sgm\n",
      "reut2-019.sgm\n",
      "reut2-020.sgm\n",
      "reut2-021.sgm\n"
     ]
    }
   ],
   "source": [
    "# For Extracting data from tar.gz files\n",
    "\n",
    "t = tarfile.open(\"G:\\\\ML\\\\Data\\\\NLP\\\\Classification\\\\reuters21578.tar.gz\", \"r\")\n",
    "for filename in t.getnames():\n",
    "    try:\n",
    "        f = t.extractfile(filename)\n",
    "        Data = f.read()\n",
    "        print (filename)\n",
    "    except :\n",
    "        print (\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file using pickle\n",
    "import pickle\n",
    "\n",
    "with open(\"extracted_text.txt\", \"wb\") as file:\n",
    "    pickle.dump(finaltext, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
